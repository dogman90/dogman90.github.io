<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      (머신러닝) Iris-flower Classification &middot; 공부 기록 블로그
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/main.css">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG"> </script>
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });
  </script>
  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <!-- <a href="http://gravatar.com/"> -->
          <a href="http://gravatar.com/"></a>
          <!-- <img src="http://www.gravatar.com/avatar/?s=350" title="View on Gravatar" alt="View on Gravatar" /> -->
          <!-- <img src="https://s.gravatar.com/avatar/fedd0cb9bf32323502b502a383136608?s=80" title="View on Gravatar" alt="View on Gravatar" style="margin:auto;" /> -->
          <img src="https://s.gravatar.com/avatar/fedd0cb9bf32323502b502a383136608?s=80" title="View on Gravatar" alt="View on Gravatar" style="margin:auto;" />
          

          
        </a>
      </div>
      <div class="sidebar-personal-info-section" >
        <p>개발자가 되고픈 사람. <br> 제대로 노력해서 1보를 이루자</p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Blog
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/categories/">
                Categories
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/tags/">
                Tags
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    

    <span class="sidebar-nav-item">Currently v1.0.0</span>
  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2020 nobbaggu. This work is liscensed under <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <!-- <a href="/" title="Home" title="공부 기록 블로그">
              <img class="masthead-logo" src=""/>
            </a> -->
            <small>개발자가 되고 싶은 사람</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">(머신러닝) Iris-flower Classification</h1>
  <span class="post-date">06 Oct 2018</span>
   | 
  
    <a href="/blog/tags/#classification" class="post-tag">classification</a>
  
    <a href="/blog/tags/#code" class="post-tag">code</a>
  
    <a href="/blog/tags/#flower" class="post-tag">flower</a>
  
    <a href="/blog/tags/#iris" class="post-tag">iris</a>
  
    <a href="/blog/tags/#machine-learning" class="post-tag">machine learning</a>
  
  
  <article>
    <pre><span style="color: #0000ff;"><span style="color: #000000;">################### Iris Flower Classification ####################
</span>
from</span> pandas <span style="color: #0000ff;">import</span> read_csv
<span style="color: #0000ff;">from</span> pandas <span style="color: #0000ff;">import</span> set_option
<span style="color: #0000ff;">from</span> numpy <span style="color: #0000ff;">import</span> set_printoptions
<span style="color: #0000ff;">from</span> matplotlib <span style="color: #0000ff;">import</span> pyplot
<span style="color: #0000ff;">from</span> pandas.plotting <span style="color: #0000ff;">import</span> scatter_matrix
<span style="color: #0000ff;">from</span> sklearn.feature_selection <span style="color: #0000ff;">import</span> SelectKBest
<span style="color: #0000ff;">from</span> sklearn.feature_selection <span style="color: #0000ff;">import</span> chi2
<span style="color: #0000ff;">from</span> sklearn.model_selection <span style="color: #0000ff;">import</span> train_test_split
<span style="color: #0000ff;">from</span> sklearn.linear_model <span style="color: #0000ff;">import</span> LogisticRegression as LR
<span style="color: #0000ff;">from</span> sklearn.discriminant_analysis <span style="color: #0000ff;">import</span> LinearDiscriminantAnalysis as LDA
<span style="color: #0000ff;">from</span> sklearn.neighbors <span style="color: #0000ff;">import</span> KNeighborsClassifier as KNC
<span style="color: #0000ff;">from</span> sklearn.pipeline <span style="color: #0000ff;">import</span> FeatureUnion
<span style="color: #0000ff;">from</span> sklearn.pipeline <span style="color: #0000ff;">import</span> Pipeline
<span style="color: #0000ff;">from</span> sklearn.model_selection <span style="color: #0000ff;">import</span> KFold
<span style="color: #0000ff;">from</span> sklearn.model_selection <span style="color: #0000ff;">import</span> cross_val_score
<span style="color: #0000ff;">from</span> sklearn.ensemble <span style="color: #0000ff;">import</span> RandomForestClassifier as RFC
<span style="color: #0000ff;">from</span> sklearn.ensemble <span style="color: #0000ff;">import</span> BaggingClassifier
<span style="color: #0000ff;">from</span> sklearn.externals.joblib <span style="color: #0000ff;">import</span> dump

<span style="color: #999999;">#### data load ####</span>
url = <span style="color: #14d917;">'https://goo.gl/mLmoIz'</span> <span style="color: #999999;">## Iris-flower classification dataset</span>
names = [<span style="color: #14d917;">'sep_len'</span>, <span style="color: #14d917;">'sep_wid'</span>, <span style="color: #14d917;">'pet_len'</span>, <span style="color: #14d917;">'pet_wid'</span>, <span style="color: #14d917;">'class'</span>]
data = read_csv(url, names = names)                
array = data.values
X = array[:,0:4]
Y = array[:,4]

<span style="color: #999999;">#### data statistics ####</span>
set_option(<span style="color: #14d917;">'display.width'</span>, 100)
set_option(<span style="color: #14d917;">'precision'</span>, 3)
print(data.describe())
print(data.skew())
print(data.corr(method=<span style="color: #14d917;">'pearson'</span>))


<span style="color: #999999;">#### visualization of data ####</span>
data.plot(kind=<span style="color: #14d917;">'density'</span>, subplots=True, layout=(2,3), sharex=False)
pyplot.show()
data.plot(kind=<span style="color: #14d917;">'box'</span>, subplots=True, layout=(2,3), sharex=False, sharey=False)
pyplot.show()
scatter_matrix(data)
pyplot.show()


<span style="color: #999999;">#### feature selection ####</span>
test = SelectKBest(score_func=chi2, k=2)
fit = test.fit(X,Y)
features = fit.transform(X)
set_printoptions(precision=3)
print(X[0:5,:])
print(features[0:5,:])
X = features <span style="color: #999999;">##pet_len, pet_width 선택</span>

<span style="color: #14d917;">"""""""""""""""""""""""""""""""""""""""""""""""""""""""""</span>
<span style="color: #14d917;">#### feature scaling ####</span>
<span style="color: #14d917;"># scaler = MinMaxScaler(feature_range=(0,1))</span>
<span style="color: #14d917;"># rescaledX = scaler.fit_transform(X)</span>
<span style="color: #14d917;"># set_printoptions(precision=3)</span>
<span style="color: #14d917;"># print(rescaledX)</span>
<span style="color: #14d917;">"""""""""""""""""""""""""""""""""""""""""""""""""""""""""</span>
<span style="color: #999999;">### feature scailing은 모델의 성능을 향상시키지 못했다.</span>

<span style="color: #999999;">#### data split to training &amp; validation test set ####</span>
X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.2, random_state=7)

<span style="color: #14d917;">"""""""""""""""""""""""""""""""""""""""""""""""""""""""""</span>
<span style="color: #14d917;">########pipeline을 통한 feature selection &amp; model selection###########</span>
<span style="color: #14d917;">features = []</span>
<span style="color: #14d917;">features.append(('KBest', SelectKBest(score_func=chi2, k=2))) #KBest 알고리즘과 LDA 알고리즘 비교</span>
<span style="color: #14d917;">features.append(('lda', LDA()))</span>
<span style="color: #14d917;">feature_union = FeatureUnion(features) #더 좋은 점수를 얻은 feature selection 알고리즘 선택</span>
<span style="color: #14d917;">models = [('LR', LR()), ('Kneighbors', KNC()), ('LDA', LDA())]#Linear Regression, K-Nearest Neighbors, LDA 알고리즘 비교</span>
<span style="color: #14d917;">kfold = KFold(n_splits=10, random_state=7) # 10개의 fold dataset</span>
<span style="color: #14d917;">for name, model in models:</span>
<span style="color: #14d917;">   estimators=[]</span>
<span style="color: #14d917;">   estimators.append(('feature_union', feature_union))</span>
<span style="color: #14d917;">   estimators.append((name, model))</span>
<span style="color: #14d917;">   model_set = Pipeline(estimators) #pipeline을 통한 가장 좋은 모델 선택</span>
<span style="color: #14d917;">   result = cross_val_score(model_set, X_train, Y_train, cv=kfold)</span>
<span style="color: #14d917;">   print('%s: %.3f%% (%.3f%%)' %(name, result.mean()*100, result.std()*100)) #accuracy score</span>
<span style="color: #14d917;">"""""""""""""""""""""""""""""""""""""""""""""""""""""""""</span>
model = LDA() <span style="color: #999999;">## LDA가 가장 좋은 모델</span>
<span style="color: #999999;">### 위 pipeline 코드의 주석을 풀고 실행시키면 LDA가 가장 좋은 점수를 받는 것을 볼 수 있다.</span>

<span style="color: #999999;">#### model evaluation ####</span>
kfold = KFold(n_splits=10, random_state=7) # 10개의 fold dataset
results = cross_val_score(model, X_train, Y_train, cv=kfold)
print(<span style="color: #14d917;">'LDA Accuracy: %.3f%% (%.3f%%)'</span> %(result.mean()*100, result.std()*100))
LDA_result = results


<span style="color: #999999;">#### improve model performance ####</span>
X = array[:,0:4]
Y = array[:,4]
X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.2, random_state=7)
<span style="color: #999999;">### 이 전 번의 LDA model의 feature selection에서 fit을 하여 feature가 2개뿐이므로 원래 데이터 다시 복구</span>


model = BaggingClassifier(base_estimator=LDA(), n_estimators=100, random_state=7)
results = cross_val_score(model, X_train, Y_train, cv=kfold)
Bagging_result = results

num_trees = 100
max_features = 3
model = RFC(n_estimators = num_trees, max_features = max_features)
results = cross_val_score(model, X_train, Y_train, cv=kfold)
RandomForest_result = results

print(<span style="color: #14d917;">'LDA Accuracy: %.3f'</span> %(LDA_result.mean()*100))
print(<span style="color: #14d917;">'LDA Bagging Accuracy: %.3f'</span> %(Bagging_result.mean()*100))
print(<span style="color: #14d917;">'RandomForest Accuracy: %.3f'</span> %(RandomForest_result.mean()*100))        

<span style="color: #999999;">#### Save model ####</span>
<span style="color: #999999;"># model.fit(X,Y)</span>
<span style="color: #999999;"># filename = 'Iris_classification_model.sav'</span>
<span style="color: #999999;"># dump(model, filename)</span></pre>

<p> </p>

<p><img class="aligncenter size-full wp-image-1187" src="/images/2018/10/no-name.jpg" alt="" width="395" height="250" srcset="/images/2018/10/no-name.jpg 395w, /images/2018/10/no-name-300x190.jpg 300w" sizes="(max-width: 395px) 100vw, 395px" /></p>

<p>위 그림은 Iris flower 꽃잎의 정보를 담고있는 각 feature의 density plot이다. sep len과 sep wid는 normal distribution을 따른다는 것을 알 수 있다. pet len과 pet wid는 feature의 local optimum이 3개로 나뉜다. 우리 data의 class가 3가지의 꽃의 종류이므로 아무래도 pet len과 pet wid 두 feature가 분류를 하는 데 결정적인 역할을 하는 feature로 보인다. 실제로 KBest feature selection 알고리즘의 결과도 pet len과 pet feature를 뽑는다.</p>

<p><img class="aligncenter size-full wp-image-1188" src="/images/2018/10/no-name-1.jpg" alt="" width="244" height="55" /></p>

<p>결과는 위와 같다. 가장 처음으로 구한 LDA model을 사용한 Ensemble(Bagging) 기법과 Random Forest Ensemble 기법 보다도 가장 먼저 구했던 LDA model의 분류 정확도가 가장 높다.</p>

  </article>
</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/2020/03/09/%ED%95%A8%EC%88%98/">
            (클린코드) Chapter03 - 함수
            <small>09 Mar 2020</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2020/03/08/%EC%9D%98%EB%AF%B8-%EC%9E%88%EB%8A%94-%EC%9D%B4%EB%A6%84/">
            (클린코드) Chapter02 - 의미 있는 이름
            <small>08 Mar 2020</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2020/03/07/%EA%B9%A8%EB%81%97%ED%95%9C%EC%BD%94%EB%93%9C/">
            (클린코드) Chapter01 - 깨끗한 코드
            <small>07 Mar 2020</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>


<div class="comments">
  <h2>Comments</h2>
  <div id="disqus_thread"></div>
  <script>
var disqus_config = function () {
  this.page.url = 'http://localhost:4000/2018/10/06/iris-flower-classification/'; // Replace PAGE_URL with your page's canonical URL variable
  this.page.identifier = '/2018/10/06/iris-flower-classification'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = '//wkimdev-gitblog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>
    
    <script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-00000000-1', 'auto');
ga('send', 'pageview');
    </script>
    
  </body>
  
  <script id="dsq-count-scr" src="//wkimdev-gitblog.disqus.com/count.js" async></script>
  
</html>

<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      (머신러닝) 14-2. Bias vs Variance &middot; 공부 기록 블로그
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/main.css">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG"> </script>
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });
  </script>
  
</head>


  <body>

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <!-- <a href="http://gravatar.com/"> -->
          <a href="http://gravatar.com/"></a>
          <!-- <img src="http://www.gravatar.com/avatar/?s=350" title="View on Gravatar" alt="View on Gravatar" /> -->
          <!-- <img src="https://s.gravatar.com/avatar/fedd0cb9bf32323502b502a383136608?s=80" title="View on Gravatar" alt="View on Gravatar" style="margin:auto;" /> -->
          <img src="https://s.gravatar.com/avatar/fedd0cb9bf32323502b502a383136608?s=80" title="View on Gravatar" alt="View on Gravatar" style="margin:auto;" />
          

          
        </a>
      </div>
      <div class="sidebar-personal-info-section" >
        <p>개발자가 되고픈 사람. <br> 제대로 노력해서 1보를 이루자</p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item " href="/blog/">
          Blog
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/categories/">
                Categories
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/tags/">
                Tags
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    

    <span class="sidebar-nav-item">Currently v1.0.0</span>
  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2020 nobbaggu. This work is liscensed under <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a>
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <!-- <a href="/" title="Home" title="공부 기록 블로그">
              <img class="masthead-logo" src=""/>
            </a> -->
            <small>개발자가 되고 싶은 사람</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">(머신러닝) 14-2. Bias vs Variance</h1>
  <span class="post-date">19 Aug 2018</span>
   | 
  
    <a href="/blog/tags/#cross-validation" class="post-tag">cross validation</a>
  
    <a href="/blog/tags/#high-bias" class="post-tag">high bias</a>
  
    <a href="/blog/tags/#high-variance" class="post-tag">high variance</a>
  
    <a href="/blog/tags/#overfitting" class="post-tag">overfitting</a>
  
    <a href="/blog/tags/#regularization" class="post-tag">regularization</a>
  
    <a href="/blog/tags/#training-data" class="post-tag">training data</a>
  
    <a href="/blog/tags/#underfitting" class="post-tag">underfitting</a>
  
    <a href="/blog/tags/#가설함수" class="post-tag">가설함수</a>
  
    <a href="/blog/tags/#머신러닝" class="post-tag">머신러닝</a>
  
    <a href="/blog/tags/#비용함수" class="post-tag">비용함수</a>
  
  
  <article>
    <p>cross validation에서 model의 hyper-parameter들을 어떻게 fit하여 모델을 개선하는지에 대해 설명한다. 결국 이 parameter들의 값을 조정한다는 것은 high bias(underfit)과 high variance(overfit) 사이에서 어떻게 균형을 맞춰나가는 지에 대한 것이다. 이러한 작업을 하는 것 역시 어느정도 시간을 들여야 하는 작업이지만, 우리가 만든 모델이 생각보다 큰 예측에러를 가지고 있는 경우 대부분은 high bias나 high variance때문인 것을 생각한다면 충분히 가치있는 일이다.</p>

<p><img class="aligncenter wp-image-549" src="/images/2018/08/no-name-75-1024x364.png" alt="" width="652" height="232" srcset="/images/2018/08/no-name-75-1024x364.png 1024w, /images/2018/08/no-name-75-300x107.png 300w, /images/2018/08/no-name-75-768x273.png 768w, /images/2018/08/no-name-75.png 1259w" sizes="(max-width: 652px) 100vw, 652px" /></p>

<p>먼저 기호를 한 번 정리하겠다.</p>

<ul>
  <li>d : 가설함수의 최고차항의 차수</li>
  <li>m : training dataset의 갯수</li>
  <li>λ : regularization parameter</li>
</ul>

<p> </p>

<p>high bias와 high variance는 training data의 cost function<img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{train}" alt="\dpi{120} J_{train}" align="absmiddle" /> 과 validation data의 cost function <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" />의 그래프를 그려놓고 보면 파악 할 수 있다. 일단 overfit인지 underfit인지 알면 위에서 말한 보조 parameter를 줄이거나 키워 조절 할 수 있게 된다.</p>

<p>#</p>

<h1 id="1-d에-따른-bias-vs-variance">1. d에 따른 bias vs. variance</h1>

<hr />

<p>가설함수의 최고차항인 d를 <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;d=1,d=2,d=3,\cdot\cdot\cdot" alt="\dpi{120} d=1,d=2,d=3,\cdot\cdot\cdot" align="absmiddle" /> 와 같이 크게하면 모델의 복잡도가 증가해 training dataset에 점점 잘 들어맞게 되면서<img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{train}" alt="\dpi{120} J_{train}" align="absmiddle" />은 작아질 것이다. 또한 어느 정도까지는 모델이 개선되기 때문에 validation data에 대한 예측 정확도도 증가할 것이다. 하지만 어느 순간을 넘어가면 high variance(overfit)이 일어난다. 이 때부터는 가설함수가 새로운 데이터에 일반화되지 못하고 오히려 validation data에 대한 예측 정확도는 떨어지면서 <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" />는 증가할 것이다.</p>

<p><img class="aligncenter size-medium wp-image-551" src="/images/2018/08/no-name-76-300x231.png" alt="" width="300" height="231" srcset="/images/2018/08/no-name-76-300x231.png 300w, /images/2018/08/no-name-76.png 562w" sizes="(max-width: 300px) 100vw, 300px" /></p>

<ul>
  <li>high bias(underfit) : <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{train}\approx&space;J_{cv}" alt="\dpi{120} J_{train}\approx J_{cv}" align="absmiddle" /></li>
  <li>high variance(overfit) : <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{train}\ll&space;J_{cv}" alt="\dpi{120} J_{train}\ll J_{cv}" align="absmiddle" />1)</li>
</ul>

<p> </p>

<p>1) <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;d=1,d=2,d=3,\cdot\cdot\cdot" alt="\dpi{120} d=1,d=2,d=3,\cdot\cdot\cdot" align="absmiddle" /> d 각각의 d에 대해 training dataset으로 모델 학습</p>

<p>2) 위에서 구한 각각의 모델로 cross validation dataset의 error <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" /> 계산</p>

<p>3) <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" />가 최소가 되는 d를 선택</p>

<p>4) test dataset의 결과를 예측하여 모델의 성능을 판단</p>

<p> </p>

<p> </p>

<h1 id="2-λ에-따른-bias-vs-variance"><strong>2. λ에 따른 bias  vs.  variance</strong></h1>

<hr />

<p><img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;\lambda=0,&space;\lambda=0.1,&space;\lambda=0.3,&space;\lambda=0.9,&space;\lambda=0.27,&space;\lambda=0.81,&space;\cdot&space;\cdot&space;\cdot" alt="\dpi{120} \lambda=0, \lambda=0.1, \lambda=0.3, \lambda=0.9, \lambda=0.27, \lambda=0.81, \cdot \cdot \cdot" align="absmiddle" /></p>

<p>보통 위와 같이 λ를 3배씩 늘려가면서 확인한다. λ는 hypothesis function의 parameter Θ를 죽여서 overfit을 해결하는 역할이다. λ가 너무 크면 오히려 high bias(underfit)이 일어나고 λ가 너무 작으면 high variance(overfit)이 일어난다.</p>

<p><img class="aligncenter size-medium wp-image-554" src="/images/2018/08/no-name-77-300x231.png" alt="" width="300" height="231" srcset="/images/2018/08/no-name-77-300x231.png 300w, /images/2018/08/no-name-77.png 562w" sizes="(max-width: 300px) 100vw, 300px" /> 1)<img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;\lambda=0,&space;\lambda=0.1,&space;\lambda=0.3,&space;\lambda=0.9,&space;\lambda=0.27,\cdot&space;\cdot&space;\cdot" alt="\dpi{120} \lambda=0, \lambda=0.1, \lambda=0.3, \lambda=0.9, \lambda=0.27,\cdot \cdot \cdot" align="absmiddle" />  각각의 λ에 대해 training dataset으로 모델 학습</p>

<p>2) 위에서 구한 각각의 모델로 cross validation dataset의 error <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" /> 계산</p>

<p>3) <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" />가 최소가 되는 λ를 선택</p>

<p>4) test dataset의 결과를 예측하여 모델의 성능을 판단</p>

<p> </p>

<p> </p>

<p> </p>

<h1 id="3-m에-따른-bias-vs-variance"><strong>3. m에 따른 bias  vs.  variance</strong></h1>

<hr />

<p>training dataset의 갯수 m에 따른 training data와 validation data의 error를 그려 보는 것으로 우리가 더 많은 dataset을 필요로 하는지 파악할 수 있는데, 이 그래프를 <span style="font-size: 14pt; color: #ff0000;"><strong>learning curves</strong></span>라고 한다.</p>

<ul>
  <li><span style="font-size: 14pt;"><strong>high bias(underfit)</strong></span></li>
</ul>

<p>model이 high bias 되어있다고 가정해보자. 이 때 training dataset의 갯수 m을 점점 늘리면 error <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{train}" alt="\dpi{120} J_{train}" align="absmiddle" />은 증가할 것이다. training data를 늘려봐야 단순한 모델로는 따라가지 못하기 때문에 error만 쌓이는 것이다. 그리고 <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" />는 m을 늘릴수록 그래도 조금씩은 작아질 것이다. 하지만 단순한 모델일수록 data에 둔감하여 새로운 데이터가 들어오더라도 모델이 잘 따라가지 않는다. 따라서 어느 시점부터는 데이터 size m이 많아지더라도 단순한 모델로는 그 데이터 패턴에 일반화되지 못해 <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" />  curve가 flat하게 되고 더 줄어들지 않는다. 평균적으로 <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{train}" alt="\dpi{120} J_{train}" align="absmiddle" />과 <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" /> 모두 높다는 것이 high bias의 특징이다.</p>

<p><img class="aligncenter size-medium wp-image-557" src="/images/2018/08/no-name-79-300x218.png" alt="" width="300" height="218" srcset="/images/2018/08/no-name-79-300x218.png 300w, /images/2018/08/no-name-79.png 522w" sizes="(max-width: 300px) 100vw, 300px" /></p>

<ul>
  <li><span style="font-size: 14pt;"><strong>high variance(overfit)</strong></span></li>
</ul>

<p>모델이 high variance 되어있다면  <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{train}" alt="\dpi{120} J_{train}" align="absmiddle" />과 <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" />의 차이가 크다. 왜냐하면 overfit이라는 것은 training dataset에는 과하게 들어맞도록 만들어 <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{train}" alt="\dpi{120} J_{train}" align="absmiddle" />는 작겠지만 새로운 데이터를 예측하는 성능은 오히려 떨어져 <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" />는 크기 때문이다. 이 때에는 training data의 갯수 m을 늘려가면 overfit이 조금씩 해결이 되고 <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{train}" alt="\dpi{120} J_{train}" align="absmiddle" />과 <img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;J_{cv}" alt="\dpi{120} J_{cv}" align="absmiddle" /> 사이의 gap이 줄어들 것이다.</p>

<p><img class="aligncenter size-medium wp-image-558" src="/images/2018/08/3-3-300x209.png" alt="" width="300" height="209" srcset="/images/2018/08/3-3-300x209.png 300w, /images/2018/08/3-3.png 561w" sizes="(max-width: 300px) 100vw, 300px" /></p>

<p> </p>

<p>위의 내용들을 토대로 model을 학습시켜 high bias나 high variance되지 않는 균형잡인 model을 만들면 새로운 data에 대한 예측확률이 올라갈 것이다.</p>

<p> </p>

<p> </p>

<p><span style="font-size: 18pt;"><strong>4. neural network(신경망)의 high bias  vs.  high variance</strong></span></p>

<hr />

<p>인공 신경망은 구조가 단순하고 parameter 갯수가 적을수록 high bias(underfit)이 일어나기 쉽고 구조가 복잡하고 parameter 갯수가 많을수록 high variance(overfit)이 일어나기 쉬운 경향이 있다. 이 때에는 신경망의 node의 갯수를 늘리거나 layer를 추가하는 식으로 high bias를 해결하고 regularization을 통해 high variance를 해결한다.</p>

<p><img class="aligncenter wp-image-559" src="/images/2018/08/no-name-78-1024x443.png" alt="" width="717" height="310" srcset="/images/2018/08/no-name-78-1024x443.png 1024w, /images/2018/08/no-name-78-300x130.png 300w, /images/2018/08/no-name-78-768x333.png 768w, /images/2018/08/no-name-78.png 1044w" sizes="(max-width: 717px) 100vw, 717px" /></p>

<p> </p>

<p>여기서 한 가지 tip을 얻을 수 있다.</p>

<p><strong>simple model</strong> : <strong><span style="color: #ff0000;">data에 둔감</span></strong> → input X 추가에 영향을 별로 받지않음 → <span style="color: #ff0000;"><strong>high bias</strong></span>(underfit)</p>

<p><strong>complex model</strong>  : <span style="color: #ff0000;"><strong>data에 민감</strong></span> → input X 추가에 큰 영향을 받음 → <span style="color: #ff0000;"><strong>high variance</strong></span>(overfit)</p>

<p> </p>

<p>신경망의 구조를 복잡하게 한 후 일반화 될 때 까지 regularization을 하여 모델을 만드는 것은 좋은 선택이다. 하지만 신경망의 구조가 복잡해질수록 계산의 시간 복잡도가 크게 증가한다. 따라서 무조건 좋은 성능을 위해 신경망을 더 복잡한 구조로 선택하는 것 보다는 hidden layer의 수를 1부터 차례로 증가시키면서 cross validation dataset에 대해 최적화시켜 hidden layer의 수를 정하는 것이 좋겠다.</p>

  </article>
</div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/2020/03/09/%ED%95%A8%EC%88%98/">
            (클린코드) Chapter03 - 함수
            <small>09 Mar 2020</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2020/03/08/%EC%9D%98%EB%AF%B8-%EC%9E%88%EB%8A%94-%EC%9D%B4%EB%A6%84/">
            (클린코드) Chapter02 - 의미 있는 이름
            <small>08 Mar 2020</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2020/03/07/%EA%B9%A8%EB%81%97%ED%95%9C%EC%BD%94%EB%93%9C/">
            (클린코드) Chapter01 - 깨끗한 코드
            <small>07 Mar 2020</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>


<div class="comments">
  <h2>Comments</h2>
  <div id="disqus_thread"></div>
  <script>
var disqus_config = function () {
  this.page.url = 'http://localhost:4000/2018/08/19/14-2-model-bias-variance/'; // Replace PAGE_URL with your page's canonical URL variable
  this.page.identifier = '/2018/08/19/14-2-model-bias-variance'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = '//wkimdev-gitblog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if (target === toggle) {
            checkbox.checked = !checkbox.checked;
            e.preventDefault();
          } else if (checkbox.checked && !sidebar.contains(target)) {
            /* click outside the sidebar when sidebar is open */
            checkbox.checked = false;
          }
        }, false);
      })(document);
    </script>
    
    <script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-00000000-1', 'auto');
ga('send', 'pageview');
    </script>
    
  </body>
  
  <script id="dsq-count-scr" src="//wkimdev-gitblog.disqus.com/count.js" async></script>
  
</html>

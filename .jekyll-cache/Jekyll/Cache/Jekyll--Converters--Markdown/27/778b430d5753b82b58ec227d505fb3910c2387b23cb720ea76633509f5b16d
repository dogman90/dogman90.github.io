I"&<p>feature 1 : 인구</p>

<p>feature 2 : 수입이 $5000 밑인 비율</p>

<p>feature 3 : 실업 비율</p>

<p>output : 100만명 당 연간 살인자 수</p>

<p><img class="aligncenter size-full wp-image-279" src="/images/2018/08/1-2.png" alt="" width="900" height="460" srcset="/images/2018/08/1-2.png 900w, /images/2018/08/1-2-300x153.png 300w, /images/2018/08/1-2-768x393.png 768w" sizes="(max-width: 900px) 100vw, 900px" /></p>

<p>일단 feature별로 절대적 수치의 scale의 차이가 커서 feature normalization을 해야한다. 그렇지 않으면 gradient descent의 속도가 너무 느릴 것이다.</p>

<p><img class="aligncenter size-full wp-image-280" src="/images/2018/08/1-3.png" alt="" width="900" height="476" srcset="/images/2018/08/1-3.png 900w, /images/2018/08/1-3-300x159.png 300w, /images/2018/08/1-3-768x406.png 768w" sizes="(max-width: 900px) 100vw, 900px" /></p>

<p>평균을 구하는 mean함수와 표준편차를 구하는 std함수는 각 column별로 연산해준다. 이렇게 normalize를 하고 나니 각 feature matrix의 각 column의 평균이 거의 0에 가깝고 표준편차는 1이 되었다. 이제 마지막으로 모든 element가 1인 column을 추가해주어 x_0라는 theta_0에 해당하는 feature를 만들어야한다. 이는 우리가 고등학교때 보았던 정규분포이다. 이제 마지막으로 모든 element가 1인 column을 추가해주어 x_0라는 theta_0에 해당하는 feature를 만들어야한다.</p>

<p><img class="aligncenter size-full wp-image-281" src="/images/2018/08/1-4.png" alt="" width="900" height="479" srcset="/images/2018/08/1-4.png 900w, /images/2018/08/1-4-300x160.png 300w, /images/2018/08/1-4-768x409.png 768w" sizes="(max-width: 900px) 100vw, 900px" /></p>

<p>이제 gradient descent를 해도 된다. 이전 글에서 implementation 할 때 썼던 cost 하수와 graD 함수를 그대로 쓰겠다. 두 함수의 내용은 다음과 같다.</p>

<p><img class="aligncenter size-full wp-image-282" src="/images/2018/08/1-5.png" alt="" width="900" height="228" srcset="/images/2018/08/1-5.png 900w, /images/2018/08/1-5-300x76.png 300w, /images/2018/08/1-5-768x195.png 768w" sizes="(max-width: 900px) 100vw, 900px" /></p>

<p>graD 함수는 theta와 J를 반환시켜주는 함수이다. gradient descent는 200번의 iteration을 거치고 마지막에는 iteration의 횟수에 따른 cost function J의 변화를 그래프로 보여주도록 했다.</p>

<p><img class="aligncenter size-full wp-image-283" src="/images/2018/08/1-6.png" alt="" width="900" height="479" srcset="/images/2018/08/1-6.png 900w, /images/2018/08/1-6-300x160.png 300w, /images/2018/08/1-6-768x409.png 768w" sizes="(max-width: 900px) 100vw, 900px" /></p>

<p>cost는 3370으로 수렴하였다. 이제 위에 계산된 theta를 최종 parameter로 정하겠다. 이제 model이 만들어졌다. 위의 model로 인구가 100만명, 수입이 $5000밑인 비율이 30%, 실업 비율이 10%인 도시의 100만명 당 연간 살인사건의 수를 예측해보겠다.</p>

<p><img class="aligncenter size-full wp-image-284" src="/images/2018/08/1-4.jpg" alt="" width="862" height="267" srcset="/images/2018/08/1-4.jpg 862w, /images/2018/08/1-4-300x93.jpg 300w, /images/2018/08/1-4-768x238.jpg 768w" sizes="(max-width: 862px) 100vw, 862px" /></p>

<p>연간 46명의 살인사건이 일어날 것으로 예상된다.</p>

<p>애석한 것은 위의 데이터들을 그림으로 나타낼 수 없다는 것이다. 우리가 그림으로 그릴 수 있는 것은 3차원 공간까지인데, feature2개와 output 1개 까지이다. feature가 3개 이상인 경우에는 feature와 output의 상간관계를 그림으로 파악하는것이 되지 않는다.</p>

<p>아무튼 개인적으로 linear regression으로 풀 수 있는 머신러닝 문제를 implementation 해보면서 이론으로 배웠던 내용들에대한 이해가 한층 더 높아진 것 같은 기분이 든다.</p>

<p>정리를 한 번 해보겠다.</p>

<p><span style="color: #ff0000;"><strong>(0. training dataset을 통해 feature matrix X, output y 만들기. 필요하다면 feature normalization 실행)</strong></span></p>

<p><span style="color: #ff0000;"><strong>1. feature 갯수에 따른 hypothesis function 생성 = theta의 갯수 정하기</strong></span></p>

<p><span style="color: #ff0000;"><strong>2. gradient descent를 통해서 cost function J가 수렴할 때 까지 theta를 update해서 최종 theta 정하기( = model 정하기)</strong></span></p>

<p><span style="color: #ff0000;"><strong>3. model로 특정한 case의 결과 예측 해보기</strong></span></p>
:ET
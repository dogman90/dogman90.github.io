I"J<p>map reduce 는 large scale dataset 을 다루는 경우 사용하는 방법들 중 하나다.</p>

<p>large scale dataset을 다루는 방법들에는 stochastic gradient descent나 mini-batch gradient descent가 있었다.</p>

<p>이 알고리즘들은 parameter를 update 하기위해 한 대의 컴퓨터만 사용했다.</p>

<p>이번에 소개할 Map Reduce는 여러대의 컴퓨터가 데이터를 나누어 가져가서 학습을 시켜 다시 master computer로 결과를 보내주어 합치는 알고리즘이다.</p>

<p> </p>

<h1 id="1-map-reduce">1. Map Reduce</h1>

<hr />

<p> </p>

<p><span style="text-decoration: underline; font-size: 14pt;"><strong>Batch Gradient Descent</strong></span></p>

<p><img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;\\for\quad&space;j=1:n\\&space;\left&space;\{&space;\theta_{j}=\theta_{j}-\frac{\alpha}{400,000,000}&space;\sum_{i=1}^{400,000,000}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}&space;\right&space;\}" alt="\dpi{120} \\for\quad j=1:n\\ \left \{ \theta_{j}=\theta_{j}-\frac{\alpha}{400,000,000} \sum_{i=1}^{400,000,000}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)} \right \}" align="absmiddle" /></p>

<p> </p>

<p><span style="text-decoration: underline; font-size: 14pt;"><strong>Map-Reduce</strong></span></p>

<p>Map Reduce에서는 여러대의 컴퓨터가 학습 데이터를 등분하여 학습 parameter를 계산한다.</p>

<p>아래는 총 4대의 컴퓨터가 4억개의 데이터를 각각 1억개씩 가져가서 학습을 시키는 경우이다.</p>

<p><img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;temp^{(1)}_{j}=\sum_{i=1}^{100,000,000}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}" alt="\dpi{120} temp^{(1)}_{j}=\sum_{i=1}^{100,000,000}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}" align="absmiddle" /></p>

<p><img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;temp^{(2)}_{j}=\sum_{i=100,000,001}^{200,000,000}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}" alt="\dpi{120} temp^{(2)}_{j}=\sum_{i=100,000,001}^{200,000,000}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}" align="absmiddle" /></p>

<p><img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;temp^{(3)}_{j}=\sum_{i=200,000,001}^{300,000,000}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}" alt="\dpi{120} temp^{(3)}_{j}=\sum_{i=200,000,001}^{300,000,000}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}" align="absmiddle" /></p>

<p><img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;temp^{(4)}_{j}=\sum_{i=300,000,001}^{400,000,000}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}" alt="\dpi{120} temp^{(4)}_{j}=\sum_{i=300,000,001}^{400,000,000}(h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}" align="absmiddle" /></p>

<p>위와 같이 계산된 값들이 master server에 전송이 되면 최종적으로 parameter는 다음과 같이 update 된다.</p>

<p><img src="https://latex.codecogs.com/gif.latex?\dpi{120}&space;\theta_{j}:=\theta_{j}-\frac{\alpha}{400,000,000}(temp^{(1)}_{j}+temp^{(2)}_{j}+temp^{(3)}_{j}+temp^{(4)}_{j})" alt="\dpi{120} \theta_{j}:=\theta_{j}-\frac{\alpha}{400,000,000}(temp^{(1)}_{j}+temp^{(2)}_{j}+temp^{(3)}_{j}+temp^{(4)}_{j})" align="absmiddle" /></p>

<p>이 작업은 완전히 Batch Gradient Descent와 동일하다. 단지 여러대의 컴퓨터가 데이터를 나누어 계산을 하기때문에 계산 속도 성능이 4배로 향상된 것일 뿐이다.</p>

<p> </p>

<p> </p>

<p> </p>

<p> </p>
:ET
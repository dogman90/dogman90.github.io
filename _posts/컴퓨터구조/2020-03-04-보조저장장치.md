---
title: (컴퓨터구조) 6. 보조저장장치
date: 2020-03-04T13:37:19+09:00
author: nobbaggu
layout: post
categories: 컴퓨터구조
tags:
  - 디스크
  - 트랙
  - 섹터
  - 플래시메모리
  - hdd
  - ssd
  - flashmemory
  - 하드디스크
  - 보조저장장치
  - raid
  - 레이드
  - nand
  - nor
  - nmos
---

## 목차 ##
----

1. 하드 디스크
2. RAID
3. 플레시 메모리와 SSD

<br>
## 0. Intro ##
----

여기에서는 가장 범용적인 하드디스크(HDD)와 RAID 디스크 배열 및 최근 사용이 확대되고있는 플래시 메모리(flash memory)와 SSD(solid-state drive)에 대해 살펴본다.

<br>
## 1. 하드 디스크 ##
----

하드 디스크의 원래 명칭은 자기적 하드 디스크(magnetic hard disk)이다. 디스크는 자화가 가능한 물질로 코팅된 원형 평판 모양이다. 평판위에 전류가 흐를 수 있는 **트랙(track)**(동심원 모양)이 여러개 존재하며 데이터들이 여기에 저장된다. **헤드(head)**라는 전도성 코일을 통해 트랙위에 전류를 흘려 디스크 표면을 자화시킴으로써 데이터를 저장하고 인출 한다. 아래 그림은 디스크의 구조를 보여준다.

![hard_disk_structure](/images/computer_architecture/6/hard_disk_structure.png){: width="50%" height="50%"}

디스크 쓰기 동작에서는 헤드의 코일에 전류를 흘릴때 나오는 자기장을 통해 자성 패턴을 디스크 표면에 기록한다. 1은 양(\+)전류로, 0은 음(-)전류로 변환되어 헤드로 보내진다. 반면 읽기 동작에서는 코일이 트랙위를 지나가면 자기 패턴에서 발생되는 유도전류가 양(\+)이면 1, 음(-)이면 0이 인출된다. 단일-헤드 디스크에서는 디스크팔의 길이를 제어해 헤드를 움직여 트랙을 선택하게되는데 이를 위한 디스크 팔과 디스크팔을 구동시키는 구동장치(actuator)가 있다.

**(1) 디스크의 구조**

디스크의 트랙 동심원들은 물리적으로는 연속적으로 연결되어있지만 논리적으로는 여러개의 섹터(sector)로 구분된다. 디스크에 데이터를 저장하거나 읽는 동작은 블록(block)단위로 이루어지며, 한 섹터의 용량이 블록하나이다. 다시말해 섹터는 디스크에 한 번 액세스동안 읽거나 쓸 수 있는 최소 단위이다.

![hard_disk_surface](/images/computer_architecture/6/hard_disk_surface.png){: width="50%" height="50%"}

트랙 사이의 간격을 트랙간 갭(gap)이라 하며 이는 트랙간의 자기장 간섭을 방지할만큼 충분한 간격이어야한다. 또한 트랙위의 섹터와 섹터 사이를 구분하기 위한 섹터간 갭이 존재한다.

최근에 개발되는 대용량 디스크들은 약 2천개 이상의 트랙과 64개 이상의 섹터들로 이루어져있다.

디스크에는 데이터 저장 밀도라는 이슈와 관련하여 크게 두 가지 방식이 존재한다. 아래 그림은 각각의 디스크 표면 구조를 보여준다.

![hard_disk_cav_mzr](/images/computer_architecture/6/hard_disk_cav_mzr.png){: width="50%" height="50%"}

**(a) CAV(Constant Angular Velocity) 방식**

트랙의 길이는 바깥쪽 동심원일수록 길어진다. CAV 방식에서는 편리성을 위해 트랙당 저장되는 데이터 비트수는 모든 트랙이 같도록 한다. 따라서 안쪽 트랙일수록 데이터 저장 밀도가 높아진다.

CAV방식에서는 중심부에 가까운 트랙이든 멀리 있는 트랙이든 데이터 액세스를 위한 회전 속도가 일정하다. 그러나 바깥쪽 트랙들의 저장밀도를 가장 안쪽 트랙에 맞추려면 저장밀도를 낮추어야하므로 저장공간이 낭비된다는 단점이 있다.

**(b) MZR(Multiple Zone Recording) 방식**

MZR 방식은 CAV 방식의 저장공간 낭비를 줄여 전체 용량을 증가시키는 다중 영역 기록 방식이라는 기술을 사용한다. 여기에서는 디스크 표면이 여러개의 동심원 영역으로 나누어지며 같은 영역의 트랙들은 같은 수의 비트를 저장한다. 결과적으로 바깥 영억의 트랙들이 더 많은 비트들을 저장할 수 있다.

<br>

헤드를 통해 트랙의 데이터에 액세스할때는 각 섹터들을 구분할 방법이 필요하다. 아래 그림을 보자.

![track_sector_data_format](/images/computer_architecture/6/track_sector_data_format.png){: width="50%" height="50%"}

위 그림은 섹터 용량이 600바이트인 트랙의 데이터 포맷을 나타낸다. 한 섹터에는 섹터를 식별하기 위한 ID필드, 데이터가 저장되는 데이터필드가 있다. 갭1은 섹터의 시작을 나타내며 갭2는 ID필드와 데이터필드 사이를 구분하기 위한 것이다. 또한 갭3은 섹터의 마지막을 나타낸다.

ID필드는 어떤 트랙의 어떤 섹터인지를 위한 섹터 식별자이다. 여러개의 디스크 평판이 존재하기때문에 평판을 나타내는 헤드번호, 평판위에서 어떤 트랙인지를 결정하는 트랙번호, 그리고 트랙위의 섹터 번호가 존재한다. SYNCH바이트는 ID필드의 시작점을 나타내기 위한 것이고 CRC는 오류검출을 위한 체크섬(checksum)이다.

515바이트의 데이터 필드에는 필드의 시작을 위한 SYNCH바이트, 그리고 데이터가 포함된다. ID필드와 같이 CRC도 포함하고 있다.

<br>
지금까지 하나의 디스크 평판 구조에 대해 설명했다. 대부분의 디스크는 평판의 양쪽이 모두 자화 물질로 코팅되어 양면을 사용하는 양면 디스크이다. 하드 디스크 드라이브(HDD)는 이러한 평판을 여러개 포함하는 다중 평판 디스크 드라이브이다.

![hard_disk_drive](/images/computer_architecture/6/hard_disk_drive.png){: width="50%" height="50%"}

디스크 드라이브의 각 디스크 표면마다 하나의 헤드가 존재한다. 디스크 팔을 움직임으로써 여러 디스크평판의 같은 위치에 있는 트랙의 데이터에 동시에 접근할 수 있다. 서로 다른 표면에 있지만 동시에 액세스할 수 있는 같은 반경의 트랙들의 집합을 실린더(cylinder)라 부른다. 위 그림의 경우 한 실린더 안에 8개의 트랙이 존재한다. 여기에서 특정 트랙을 선택하기 위해 발생되는 주소에는 실린더 번호, 헤드 번호, 섹터 번호로 이루어진다.

<br>
**(2) 디스크 액세스 시간**

디스크의 특정 데이터블록에 액세스하는 과정은 아래와 같다.

	(a)헤드를 해당 트랙으로 이동 : 탐색시간
	(b)데이터블록이 저장된 섹터가 헤드 아래로 올 때 까지 회전 : 회전 지연시간
	(c)데이터 전송 시간
	
데이터에 대한 액세스 시간은 위의 시간들을 모두 합친것이다.

탐색시간은 기계적인 이동으로 시동시간이 포함된다. 액세스할 데이터들이 가까운 트랙들에 위치하고 있으면 이 시간이 단축된다. 회전 지연시간은 디스크의 회전속도에 좌우된다. 대부분의 HDD는 5400rpm이나 7200rpm의 회전속도를 가진다.

<br>
## 2. RAID ##
----

디스크의 속도는 주기억장치(메모리)에 비해 10만분의 1 정도밖에 되지않는다. 특히 디스크 입출력이 많이 발생하는 프로그램의 경우 CPU, 메모리와 보조저장장치 사이의 속도 불균형에 의해 성능이 크게 제한될 수 밖에 없다. 또한 CPU와 주기억장치의 발전속도를 따라가지 못하여 그 차이는 더 커질 것으로 예상된다.

RAID(Redundant Array of Independent Disks)는 작은 디스크 여러개를 배열구조로 연결하여 패키징한 유닛으로 디스크의 액세스 속도를 크게 향상시키면서 신뢰도 또한 높이는 기술이다.

<br>
**(1) RAID의 출현 배경**

디스크의 저장 밀도가 높아짐에따라 비트당 가격이 계속해서 떨어지고 용량이 증가하고있다. 이에따라 하나의 대형디스크보다는 여러개의 소형 디스크를 연결하는것이 저렴한 가격으로 더 큰 용량의 디스크를 구성할 수 있게 해준다. 이렇게하면 용량뿐아니라 프로그램 실행에 직접적인 영향을 주는 속도 문제또한 개선이된다. 속도개선을 위해서는 액세스 시간 단축과 전송시간 단축이 필요하다. 데이터를 다수의 디스크에 분산하여 저장하게되면 여러 디스크들에 대한 동시 액세스와 데이터 병렬 전송이 가능해진다.

하나의 파일을 구성하는 데이터 블록들을 여러 디스크에 분산 저장하는 기술을 **디스크 인터리빙(disk interleaving)**이라고 한다. 아래 그림은 16개의 데이터 블록들이 4개의 디스크에 균등하게 분산 저장된 모습을 보여준다.

![disk_interleaving](/images/computer_architecture/6/disk_interleaving.png){: width="50%" height="50%"}

위 그림과 같이 데이터를 분산저장하면 여러개의 블록에대한 동시 액세스가 가능해지고 하나의 디스크에 집중되는 현상을 줄임으로써 병목현상도 줄일 수 있다. 그러나 디스크들 중 1개만 고장이나도 데이터 파일이 손상된다는 문제점이 있다.

아래 표는 IBM3390의 대형 디스크와 IBM0061 소형 디스크, 그리고 IBM0061을 배열구조로 연결하여 IBM3390과 동일한 용량을 가지도록한 RAID방식 디스크를 비교한 표이다.

![disk_comparison](/images/computer_architecture/6/disk_comparison.png){: width="50%" height="50%"}

크기, 전력소모, 데이터 전송률, 시간당 입출력 처리, 가격 모든 면에서 RAID 방식이 우수하다. 그러나 RAID방식의 주요 단점은 MTTF(Mean Time To Failure)가 낮다는 것이다. MTTF는 고장이 발생하는 시간 주기의 평균값이다. IBM 3390의 MTTF가 25만 시간이란 것은 평균적으로 25만 시간당 한 번 고장이 발생한다는 의미이다. RAID 방식은 여러 디스크를 연결한 것이므로 여러개 중 한 개만 고장이 나도 전체 디스크의 사용이 불가능해지므로 MTTF가 낮은 것이다.

디스크 배열의 결함 허용(fault-tolerance)를 높이기 위해 많은 노력들이 있었다. 그 중 하나는 여분의 디스크를 추가해 오류검출 및 데이터 백업을 하는 것이다. 즉, 배열내 하나의 디스크에 결함이 생기면 해당 디스크의 사용이 중지되고 여분의 검사 디스크에 저장된 변경 히스토리를 기반으로 원래의 정보를 재구성하여 여분의 디스크에 저장하게 된다. 복구되는데 소요되는 평균 시간을 MTTR(Mean Time To Repair)라고 한다. 이러한 복구작업은 시스템에 의해 자동으로 일어난다.

오류검출 및 정정(error detection and correction) 방법에 따라 여러종류의 RAID 조직이 제안되어왔다.

<br>
**(2) RAID의 종류**

<br>
**(a) RAID-1**

![raid1](/images/computer_architecture/6/raid1.png){: width="50%" height="50%"}

데이터를 중복 저장하는 미러 디스크가 존재한다. 디스크 미러링 이라고 한다.

하나의 디스크에 결함이 발생하면 그 디스크의 모든 데이터가 미러 디스크에 존재하므로 데이터를 잃어버릴 염려가 없게된다. 또한 결함복구 시간이 필요하지 않다.

데이터 쓰기 동작은 데이터 디스크와 미러 디스크 모두에 대해 수행되어야 한다. 헤드의 위치 차이에 따른 탐색 시간차가 존재할 경우 더 오랜 탐색시간을 요구하는 디스크의 쓰기가 완료되어야 쓰기가 끝난다. 읽기 동작에서는 두 디스크 중 더 짧은 탐색시간과 회전 지연시간을 요구하는 디스크에서 수행하면 된다.

데이터 디스크를 통체로 미러링하기 위해서 두 배의 디스크가 필요하므로 가격이 높다. 따라서 RAID-1은 높은 신뢰도를 요구하는 시스템에 주로 사용된다.

<br>
**(a) RAID-2**

이 구조는 데이터를 비트 단위로 인터리빙 시킨다. 한 단어를 이루는 비트들을 여러 디스크에 분산시켜 저장하는 것이다.

![raid2](/images/computer_architecture/6/raid2.png){: width="50%" height="50%"}

검사 디스크들은 오류검출 및 정정을 위한 패리티 비트들을 저장한다. 즉, 검사디스크들을 추가하고 해밍 코드(Hamming Code)를 사용하면 에러를 검출할 수 있고 심지어 어떤 비트에서 에러가 났는지를 알 수 있다.

여담이지만 위성신호나 TV와 같은 실시간 디지털 신호에서는 데이터를 받고 에러가 있으면 즉시 정정을 해야하므로 해밍 코드가 유용하다. 다만 필요한 검사 디스크의 수가 데이터 디스크 수의 로그에 비례하므로 가격이 높다. 이러한 이유로 많은 오류가 발생하거나 높은 신뢰도를 요구하는 시스템에서 주로 사용한다.

<br>
**(a) RAID-3**

RAID-3은 RAID-2에서 오류 비트의 위치검출을 위한 많은 수의 디스크 사용에 따르는 낭비를 보완하기 위한 것이다. 1개의 패리티 디스크만 추가한다. 

![raid3](/images/computer_architecture/6/raid3.png){: width="50%" height="50%"}

데이터 디스크들의 동일한 위치에 있는 비트들에 대한 패리티 비트가 패리티 디스크의 동일한 위치에 저장된다.

만약 한 디스크에 결함이 발생한다면 해당 비트는 다른 디스크의 비트들과 패리티비트 간의 XOR 연산을 통해 구할 수 있다. 만약 위 그림에서 b1b2b3b4 = 1001이라면 짝수 패리티에서 패리티비트 p=0이 저장된다. 그리고 2번째 디스크가 고장난다면 b2=p XOR b1 XOR b2 XOR b3 = 0 XOR 1 XOR 0 XOR 1 = 0이 된다.

RAID-3에서는 모든 데이터가 비트단위로 분산 저장되기때문에 데이터 액세스 과정에서 모든 디스크에 병렬적으로 액세스하게된다. 따라서 액세스 시간이 단축되며 병렬 전송에 의해 데이터 전송률도 올라간다. 단점으로는 쓰기 동작마다 패리티비트를 업데이트 해주어야 하기때문에 쓰기 시간이 오래 걸린다. 또한 하나의 데이터 액세스에서 모든 디스크가 사용되므로 한 번에 하나의 요청만 처리할 수 있다.

<br>
**(a) RAID-4**

RAID-4에서는 아래 그림과 같이 데이터 블록 단위 디스크 인터리빙을 사용한다. 여기서 패리티 디스크를 하나 추가하여 패리티 블록을 저장한다.

![raid4](/images/computer_architecture/6/raid4.png){: width="50%" height="50%"}

패리티 블록은 각 디스크의 블록을 XOR 연산하여 구할 수 있다.

그런데 어느 한 디스크의 내용이 변경되면 패리티 블록의 내용이 변경되어야하고 패리티블록의 계산을 위해서는 변경되지않은 나머지 디스크들에 있는 데이터 블록들도 필요하다. 그리고 디스크의 수가 증가될수록 필요한 읽기/쓰기 동작의 수가 증가한다.

만약 B2의 내용이 B2'로 변경되었다면 패리티블록은 P' = B1 XOR B2' XOR B3 XOR B4가 된다. 여기에 조금의 수학적 테크닉을 추가해보자.

P' = B1 XOR B2' XOR B3 XOR B4 XOR (B2 XOR B2) (B2 XOR B2는 0이므로 원래의 식에 영향을 주지않는다.)

위 식을 정리하면 P' = B1 XOR B2 XOR B3 XOR B4 XOR (B2 XOR B2') = P XOR B2 XOR B2'

새로운 패리티블록의 계산을 위해서는 기존의 P와 B2를 가져오는 2번의 읽기와 B2'와 P'를 쓰는 두 번의 쓰기만 필요로하며 디스크의 수가 늘어나도 일정하다.

그러나 어떤 디스크에 데이터를 쓸 때마다 패리티 디스크에 두 번씩 액세스 되어야하므로 액세스가 집중되고 이에따른 병목현상이 발생하여 성능저하가 일어난다.

<br>
**(a) RAID-5**

RAID-5는 RAID-4의 패리티 디스크에 대한 병목현상을 해결하기 위해 고안된 구조이다. 따라서 설계개념은 RAID-4와 동일하고 패리티 블록을 여러 디스크에 분산 저장한다는 점만 다르다.

![raid5](/images/computer_architecture/6/raid5.png){: width="50%" height="50%"}

위 그림처럼 패리티 블록을 분산시켜 RAID-4에서 하나의 패리티 디스크에 몰리던 액세스 요청을 여러 디스크로 분산시켰다. 또한 쓰기 동작이 여러 디스크에 대해 동시에 수행 가능하다는 점이다. B1에 쓰기 위해서는 1, 5번째 디스크에대한 액세스가 필요하고 B7에 쓰기 위해서는 3, 4번째 디스크에 대한 액세스가 필요하다. 따라서 겹치는 부분이 없는 경우 동시 쓰기가 가능하다.

<br>
현실에서는 주로 RAID-1과 RAID-5가 사용된다. 큰 데이터를 쓰는 경우에는 RAID-1이 미러 디스크까지 2배로 써야하기때문에 성능이 좋지 않지만 작은 데이터를 여러 번 쓰는경우 RAID-5는 매 쓰기마다 4번의 액세스가 필요하여 오버헤드가 증가하게 된다. 또한 가격대비 성능 측면에서는 RAID-5가 더 우수하다. 결론적으로 구성하려는 시스템의 목적에 맞는 방식의 디스크 배열을 선택하면 된다.

<br>
## 3. 플래시 메모리와 SSD ##
----

기계적 장치를 많이 포함하는 하드디스크의 속도 한계때문에 새로운 유형의 보조저장장치가 출현하였다. SSD(Solid State Drive)는 반도체로 만들어진 보조저장장치이다. SSD는 EEPROM의 한 종류인 플래시메모리를 사용해서 만든다.

플래시 메모리(flash memory) 칩들을 배열구조로 패키징하여 만든것이 SSD이다. SSD는 하드디스크에 비하여 속도가 훨씬 빠르다.

<br>
**(1) 플래시 메모리**

전기적 삭제가 가능한 EEPROM이 개발된 초기에는 1bit를 저장하는 하나의 셀(cell)이 두 개의 트랜지스터로 만들어져 부피가 컸다. 따라서 가격과 저장밀도 면에서 디스크를 대체할 정도로는 부각되지 못했었다.

그러나 최근 한 개의 트랜지스터를 사용하여 1bit를 저장하면서 전력소모가 낮고 신뢰성도 높은 플래시 메모리가 개발되었다.

<br>
**(a) 동작 원리**

플래시 메모리에서 하나의 셀(cell)은 NMOS 트랜지스터가 사용된다.

![flash_memory_cell](/images/computer_architecture/6/flash_memory_cell.png){: width="50%" height="50%"}

일반적인 NMOS와 다른점은 게이트가 2개라는 것이다. 여기서 부동게이트가 데이터를 저장하는 핵심적인 역할을 수행한다. 부동 게이트는 산화막(이산화규소-SiO2)으로 둘러싸여있어 전자들이 쉽게 통과할 수 없도록 되어있다.

제어게이트에 5V를 걸어주면 소스와 드레인 사이에 전자가 통과할 수 있는 채널이 형성된다. 그런데 일정수준 이상의 전압(12V)을 걸어주면 채널은 통과하는 전자가 강한 전기장에 의해 산화막을 뚫고 부동게이트로 들어오게 된다. 이를 전자의 터널 주입이라 한다. 인가되었던 전압이 사라지면 부동게이트 안의 전자들은 그대로 갇히게 된다. 이것이 플래시 메모리의 '쓰기' 동작으로 0을 저장한 것이다.

반대로 정공으로 차있는 p-well쪽에서 강한 전압을 인가하면 부동게이트에 갇혀있던 전자들이 산화막을 통과하여 N채널로 빠져나오게 되어 부동게이트는 비게 된다. 이것이 플레시 메모리의 '삭제' 동작이며 셀을 논리적 1 상태로 만든 것이다.

읽기 동작을 이해하기 위해 아래 그림을 보자.

![flash_memory_read](/images/computer_architecture/6/flash_memory_read.png){: width="50%" height="50%"}

게이트에 5V전압을 인가하여 N채널을 형성해주고 소스를 접지시키고 드레인에 5V전압을 인가하면 전류가 흐르게된다. 이 때 셀의 부동게이트가 비어있으면(1) 게이트의 5V전압이 p-well의 정공들을 밀어내게되고 채널이 충분히 넓어져 충분한 양의 전류가 흐르게된다. 만약 셀의 부동게이트가 전자로 채워져있으면(0) 게이트 전압이 형성하는 전기장이 이 전자들에의해 차단되고 N채널이 전자가 흐를만큼 넓어지지 못하게되고 전류가 흐를 수 없게 된다.(사실 미약한 누설전류가 흐른다.)

결론적으로 소스와 드레인 사이에 전압을 걸어주었을 때 전류가 흐르면 1, 흐르지 않으면 0인 것이다. NMOS 셀들로 이루어진 플레시 메모리는 비휘발성 보조장치 역할을 할 수 있는것을 알았다.

<br>
**(b) NOR형 플래시와 NAND형 플래시**

NMOS셀의 연결방식에 따라 플래시 메모리의 종류가 결정된다.

![nor_nand](/images/computer_architecture/6/nor_nand.png){: width="50%" height="50%"}

NOR형에서는 모든 셀이 5V가 인가되는 비트선(BL - Bit Line)과 접지선 사이에 병렬연결이 되어있다. 이 중 어느하나라도 1이면(부동게이트가 비어있으면) 게이트 전압이 걸렸을 때 전류가 흘러 비트선(BL)이 0V로 떨어지게 된다. 이는 NOR 연산에 해당하므로 NOR형 플래시라 불린다. 참고로 제어게이트에는 단어 선(WL - Word Line)이 연결되어있어 단어선에 의해 전압이 인가된다. NOR형 플래시에서는 셀 별로 선택신호를 인가하여 저장된 값을 읽을 수 있다. 비트선의 선은 출력단에서 감지 증폭기(sense amplifier)에 의해 반전되어 출력되므로 0V가 1로, 1V가 0으로 반전되어 출력된다.

<br>
반면 NAND형에서는 NMOS 셀들이 BL과 GND 사이에 직렬로 연결되어있다. NAND 플래시에서는 각 셀에 전류가 흐르기 위한 문턱 전압(threshold voltage)이 저장된 정보에 따라 다르다. 부동게이트가 비어있는 '1' 상태에서는 문턱전압이 -3V이고 전자로 채워진 '0' 상태에서는 문턱전압이 \+1V가 된다.

초기 상태에서 모든 게이트로 5V를 인가하면 저장상태에 상관없이 모든 셀이 ON되고 전류가 흘러 BL이 0V로 떨어진다. 이후 셀을 하나씩 선택하면서 0V를 인가해본다. '1' 상태에서는 그대로 BL이 0V일것이고 '0'상태라면 문턱전압보다 낮아져 전류가 끊기게 되어 BL이 5V로 유지된다. 이런 식으로 모든 셀의 정보를 읽을 수 있다. 0V가 인가된 셀의 저장상태가 '0'이라면 다른 셀의 상태에 상관없이 전류가 흐르지 못해 5V가 된다. 이는 NAND 연산에 해당되므로 NAND 플래시라 불린다.

<br>
NOR 플래시에서는 각 셀 단위의 읽기/쓰기가 가능하나 셀별로 BL과 GND 접속선을 따로 두어야하므로 부피가 커진다. 반면 NAND 플래시는 BL은 최상단 트랜지스터의 드레인으로, GND는 최하단 트랜지스터의 소스로만 접속되어 연결선의 수가 대폭 줄어 부피가 작다.

NOR 플래시는 비트 혹은 바이트 단위의 읽기 쓰기가 가능하기 때문에 고정된 프로그램 코드를 순차적으로 가져오거나 작은 크기의 데이터를 수시로 읽고 쓰는데 적합하다. 따라서 BIOS 저장, 스마트폰OS 저장 등에 쓰인다. 그러나 부피문제로 대용량 보조저장장치로는 적합하지 않다. SSD 이외의 보조저장장치로는 가격이 싸고 칩 당 용량이 큰 NAND 플래시가 더 적합하다.

<br>
**(c) 내부 구조**

여기서는 보조저장장치의 용도에 맞는 NAND플래시에 집중한다.

NAND플래시는 블록(block)들로 구분되고 각 블록은 페이지(page)들로 이루어져있다. 아래 그림은 1Gbit = 128MByte NAND플래시 구조의 예시를 보여주고 있다.

이 그림에서 오른쪽의 그림은 화면에 수직하는 방향으로 8개가 겹쳐있다고 가정한다. 2048×8bit = 2KByte의 페이지들이 64개 모여 하나의 블록을 구성한다. 읽기/쓰기 동작에서는 페이지 선택 해독기에 의해 페이지 전체가 액세스 된다. 따라서 NAND플래시의 읽기/쓰기 동작은 페이지 단위로 이루어진다. 반면 삭제 동작은 블록 단위로만 이루어진다.

플래시 메모리의 유형으로는 블록당 페이지수가 32, 64, 128개 등 다양하고 페이지 크기도 2, 4, 16, 64KByte로 다양하다.

<br>
**(3) SLC, MLC, TLC**

SLC(Single Level Cell)는 기존의 셀을 나타낸다. SLC에서는 부동게이트에 전자가 채워졌는지 비었는지에 따라 0과 1로 구분했다. 그런데 차있는 양에따라 구분하는 기술이 개발되었다.

MLC(Multi Level Cell)은 전차가 차있는 양을 4단계로 구분하기 때문에 4가지 상태(00 01 10 11)를 나타낼 수 있어 총 2bit를 저장할 수 있다. 아래 그림은 SLC와 MLC의 전자수에 의한 상태구분을 보여준다.

![flash_memory_read](/images/computer_architecture/6/flash_memory_read.png){: width="50%" height="50%"}

TLC는 부동게이트에 차있는 전자의 양을 8단계로 구분하여 총 3bit를 저장할 수 있도록 한 것이다.

그러나 MLC나 TLC에서는 쓰기 과정에서 부동게이트에 주입되는 전자수의 조정을 위한 세밀한 작업이 요구되고 읽기 과정에서 상태 사이의 구분이 쉽지 않아 오차가 존재할 수 있다. 또한 액세스 및 삭제시간이 길어진다.

<br>
**(4) 3D NAND 플래시**

반도체 제조공정이 미세화됨에 따라 기존의 셀 구조를 변형시킨 후 이를 위로 쌓아올린 3차원 NAND 플래시 구조가 가능해졌다.

![3d_nand_cell](/images/computer_architecture/6/3d_nand_cell.png){: width="50%" height="50%"}

기존의 셀과 다르게 원통형 모양으로 셀을 만들어 이를 수직으로 여러 겹 쌓아올린다. 위 그림에서는 24개의 셀을 적층했다. 이 때 셀 사이에 간격을 줌으로써 2D에서 집적도를 올리는데 방해가 되었던 셀 간의 데이터 간섭 현상도 해결된다. 또한 부동게이트의 크기가 커짐에따라 전자 수의 구분이 용이해져 오류가 줄어들고 심지어 4bit를 저장할 수 있는 QLC(Quadruple Level Cell)을 제조하는것도 가능해졌다. 이로인해 테라 비트(tera bit)급의 칩들도 출현하고 있다.

<br>
**(2) SSD**

SSD(Solid State Driver)는 여러개의 NAND 플래시 메모리를 배열로 구성한 패키지이다. 따라서 RAID구조처럼 여러개의 칩에 동시 액세스 및 병렬 데이터 전송이 가능하여 성능을 더욱 높여준다.

앞에서 말했듯이 플래시 메모리는 블록과 페이지 단위로 이루어져 있으며 크기 또한 하드디스크(HDD)의 트랙 및 섹터와 다르다. 따라서 기존의 운영체제 파일시스템은 SSD를 HDD와 같은 방식으료  사용할 수 없다는 문제가 있다. 이를 해결하기 위해 SSD 제어기에서는 플래시 변환 계층(FTL - Flash Translation Layer)라는 미들웨어를 제공한다. FTL은 운영체제가 SSD의 블록과 페이지를 논리적으로 HDD의 트랙 및 섹터구조로 변환해준다. 아래 그림은 이 관계를 보여준다.

![ftl](/images/computer_architecture/6/ftl.png){: width="50%" height="50%"}

FTL은 페이지와 섹터 사이의 매핑(mapping) 이외에도 중요한 기능들을 수행한다.

<br>
**(a) 마모 평준화(wear leveling)**

플래시 메모리의 셀은 재기록 반복횟수 제한이 있고 MLC, TLC, QLC는 그 횟수가 더욱 줄어든다. 그런데 만약 재기록이 특정 블록이나 페이지에 집중된다면 그 부분이 일찍 마모되어 칩 전체 수명이 짧아진다. FTL은 모든 페이지들이 고르게 사용되게 하는 마모 평준화를 수행한다.

SSD 제어기는 재기록 레지스터에 페이지별로 재기록 횟수를 카운트하고 이를 참고하여 더 적게 사용된 페이지가 선택되도록 한다.

<br>
**(b) 쓰레기 수집(garbage collection)**

SSD를 구성하는 플래시 메모리에서 삭제 작업은 블록(block) 단위로만 일어난다. 따라서 특정 페이지의 내용을 수정하는 경우에 그 페이지를 즉시 지우지는 않고 그대로 둔다. 일단 수정된 내용들과 다른 유효 페이지들만 다른 블록에 기록한다. 이 결과로 해당 블록에는 수정되었지만 지우지 않은 무효 페이지들이 점점 쌓이게 된다. 이런 과정이 반복된 이후 무효 페이지들이 많이 축적된 블럭이 있으면 한꺼번에 삭제동작을 수행한다.

운영체제는 TRIM 명령어를 통해 SSD 제어기에게 무효 페이지가 생길때마다 알려주어 쓰레기 수집의 효율을 높인다.

<br>
**(c) 초과 대비공간(over-provisioning)**

마모 평준화나 쓰레기 수집은 여유공간이 어느정도 남아있을 때 효율적으로 이루어질 수 있다. 따라서 SSD 제품들은 출시될 때 부터 일부를 이 작업에 대비한 공간으로 사용하도록 지원한다. 예를들어 삼성의 MZ-7TD250B는 256GB의 용량 중 6GB를 초과 대비공간으로 남겨둔다.

---
title: (컴퓨터구조) 5. 기억장치(메모리)
date: 2020-02-24T13:37:19+09:00
author: nobbaggu
layout: post
categories: 컴퓨터구조
tags:
  - 메모리
  - 기억장치
  - RAM
  - 액세스
  - 직접액세스
  - 임의액세스
  - 직접액세스
  - 연관액세스
  - 액세스
  - 랜덤액세스
  - access
  - direct
  - random
  - sequential
  - 대역폭
  - 휘발성
  - 비휘발성
  - 해독기
  - 디코더
---

## 목차 ##
----

1. 기억장치의 분류와 특성
2. 계층적 기억장치시스템
3. 반도체 기억장치
4. 기억장치 모듈의 설계
5. 캐시 메모리
6. DDR SDRAM
7. 차세대 비휘발성 기억장치

<br>
## 0. Intro ##
----

기억장치는 말그대로 데이터를 저장하기 위한 하드웨어를 말한다. 기억장치는 크게 내부 기억장치와 외부 기억장치로 나뉜다. 내부 기억장치는 흔히 알고있는 메모리로서 CPU가 직접 액세스할 수 있다. 외부 기억장치는 디스크나 외장하드, CD-ROM과 같은 보조 저장장치의 용도로 사용되며 CPU가 직접 액세스 할 수 없다.

이번 챕터에서는 일반적으로 메모리라고 부르는 내부 기억장치에 대해 설명한다.

<br>
## 1. 기억장치의 분류와 특성 ##
----

기억장치의 데이터를 읽거나 쓰기 동작을 액세스(access)라고 한다. 기억장치는 제조 공정과 구조에 따라 액세스 방법이 달라지는데 그 유형은 아래와 같다.

**1) 순차적 액세스(sequential access)**

처음부터 순차적으로 액세스한다. 이 방식의 예시로는 자기 테이프(magnetic tape)이 있다. 데이터는 레코드(record)라 불리는 단위로 구분되며 각 레코드별로 주소가 할당되어있다. 한 쪽으로 감겨있는 자기테이프의 특정 위치에 데이터를 쓰기 위해서는 그 위치까지 재생시켜 통과시켜야한다. 즉, 특정 위치에 액세스하기 위해서는 시간이 걸린다.

**2) 직접 액세스(direct access)**

데이터가 레코드 혹은 블록으로 구분지어져있다. 특정 블록 내의 특정 위치에 액세스를 하기위해서는 해당 블록의 처음 위치로 이동한 후 그 위치까지 순차적 액세스를 실행해야한다. 직접 액세스를 사용하는 장치로는 CD-ROM, DVD등이 있다.

**3) 임의 액세스(random access)**

별도의 일기/쓰기 회로가 존재한다. 따라서 어떤 위치로든 바로 액세스할 수 있다. 특정 위치까지 이동하는 시간이 필요없고 어느 위치로 액세스하던지 같은 시간이 걸린다. 반도체 기억장치들이 임의 액세스 방식을 사용한다.

**4) 연관 액세스(associative access)**

임의 액세스를 응용한 방식이다. 다른점은 키(key)와 값(value)이 같이 저장되어있다. 임의 액세스가 주소를 통하여 액세스 하는것과 다르게 키를 이용하여 액세스한다. 즉 액세스 요구에는 주소가 아닌 키의 비트 패턴이 포함되고 이를 데이터의 각 키와 비교하여 일치하는 곳으로 액세스한다. 중요한 점은 키 값을 하나씩 순차적으로 비교하는 방식이 아닌 동시에 모든 키들과 비교하므로 액세스 시간이 소요되지 않는다는 점이다.

<br>

기억장치 시스템에서는 저장할 수 있는 용량(capacity)와 액세스 속도(access speed)가 중요하다. 이와 관련된 기억장치의 개념을 몇 가지 알아보자.

**a) 전송 단위(unit of transfer)**

CPU가 한 번에 액세스할 수 있는 메모리의 비트 수이다. 다시말해 CPU와 메모리 사이에 연결된 데이터 선의 수와 같다.

**b) 주소지정 단위(address unit)**

하나의 주소에 할당된 메모리 용량이다. 일반적으로 바이트(byte)가 주소지정 단위이다. 때로는 워드(word)를 사용하기도 한다. 만약 CPU가 주소지정을 위해 사용하는 비트수가 A라면 2^A개의 주소가 지정될 수 있다. 이 때 주소지정단위가 BYTE라면 사용할 수 있는 메모리 크기는 2^A 바이트가 된다. 혹은 주소지정단위가 워드(word)이고 1워드가 4바이트라면 4\*2^A 바이트만큼의 메모리를 사용할 수 있다.

<br>
프로그램의 성능에 직접적인 영향을 끼치는 메모리의 액세스 속도와 관련된 몇 가지 파라미터들에 대해 알아보자.

**1) 액세스 시간(access time)**

읽기/쓰기 신호가 메모리에 도착한 순간부터 읽기/쓰기가 완료되는데 걸리는 시간이다. 순차적 액세스 방식이나 직접 액세스에서는 데이터가 저장된 위치별로 다르지만 랜덤 액세스 방식을 사용하는 메모리에서는 데이터가 저장된 위치, 즉 주소에 상관없이 액세스 시간이 동일하다.

**2) 기억장치 사이클 시간(memory cycle time)**

최근에 개발되고 있는 FRAM같은 경우는 데이터를 읽은 후에는 데이터가 소멸되고 다시 자동적으로 복원된다. 기억장치 사이클 시간은 액세스 시간과 데이터 복원시간을 합친 것이다. 우리가 흔히 알고있는 반도체 메모리같은 경우는 액세스시간과 기억장치 사이클시간이 같다.

**3) 데이터 전송률(data transfer rate)**

1초당 읽거나 쓸 수 있는 비트 수를 말한다. 예를들어 액세스 시간이 100ns이고, 전송단위가 1바이트라면 데이터 전송률은 1byte/100ns = 10MByte/s가 된다.

<br>
추가적으로 메모리 제조에 사용되는 재료에 의한 구분도 있다. 크게 반도체 메모리, 자기표면 메모리, 광 메모리 등이 있다. 자기표면 기억장치나 광학 메모리는 비휘발성인데 반해 반도체 메모리는 휘발성, 비휘발성 두 종류가 있다.

<br>
## 2. 계층적 기억장치시스템 ##
----

컴퓨터 성능에서 가장 큰 부분을 차지하는 CPU의 속도는 매우 향상되었다. 그러나 기억장치의 처리속도가 느리다면 CPU가 아무리 빠르더라도 메모리에서 병목현상이 일어난다. 대기시간만큼 컴퓨터는 느려질 수 밖에 없다. 따라서 메모리 액세스 시간 또한 컴퓨터 성능에서 매우 중요한 부분을 차지한다.

이번 평균 액세스 속도는 높이면서 성능대비 가격도 적절히 유지할 수 있도록 적절한 계층적 기억장치 시스템(hierarchical memory system)을 구성하는 방법과 효과에 대해 알아본다.

<br>
**1) 필요성 및 효과**

주기억장치와 CPU 사이의 속도차이도 문제지만 대용량 저장을 위한 일반적인 보조저장장치(디스크)는 일반적으로 메모리보다 액세스 속도가 10만배 가량 느리다. 따라서 메모리의 크기가 작으면 한 번에 올릴 수 있는 데이터량이 작으므로 필요할 때 마다 디스크 입/출력이 발생하므로 그만큼 성능저하는 더욱 심각해진다. 즉, 메모리의 용량이 클수록 더 많은 데이터를 CPU 가까이 위치시킬 수 있기 때문에 액세스 시간은 짧아진다. 그러나 부피 문제와 가격 문제로 인해 메모리 크기를 무한정 키울 수 없다.

메모리를 구성할 때는 속도뿐만 아니라 기능, 용량 및 가격까지 고려해야한다. 이러한 여러 조건들을 충족시키기 위해 여러개의 다른 종류의 기억장치들을 분리하여 계층적으로 구성한다. 캐시 메모리, 레지스터, 범용 메모리 등으로 나누는 이유가 이 때문이다. 즉, 컴퓨터 시스템에서 기억장치를 구성할 때는 속도, 용량, 가격 사이의 trade-off가 필요하다.

기억장치의 속도, 용량, 가격 사이에는 아래와 같은 관계들이 성립한다.

**a) 액세스 속도가 높아질수록 비트당 가격이 높다**

**b) 용량이 커질수록 비트당 가격은 낮다**

**c) 용량이 커질수록 액세스 속도는 낮다**

따라서 컴퓨터의 사용 목적에 따라 더 크고 싸지만 속도는 느린 메모리를 구성할지, 가격은 비싸지만 액세스 속도가 빠른 메모리 종류를 추가할지를 결정하면 된다.

아래 그림은 계층적 기억장치 시스템을 구성함으로써 얻을 수 있는 이점을 설명하기 위한 그림이다.

![hierarchical_memory_model](/images/computer_architecture/5/hierarchical_memory_model.png){: width="50%" height="50%"}

위 그림에서 L1 메모리의 액세스 시간이 10ns, L2 메모리의 액세스 시간이 100ns라고 가정하고, 두 메모리만을 사용한다고 해보자.

프로그램 실행 과정에서 필요한 데이터의 50%가 L1, 나머지 50%가 L2에 있다고 가정했을 때 평균 액세스 시간은 0.5\*10ns + 0.5\*100ns = 55ns이다. 만약 8:2 비율로 있다면 28ns이다. 모든 데이터가 L1에 있다면 평균 액세스시간은 10ns가 된다.

일반적인 프로그램이 실행되는 동안에 액세스하는 메모리의 위치를 조사해보면 특정 구역에 집중되는 경향이 있다. 그 이유는 대부분의 프로그램이 특정 반복문이나 서브루틴 함수를 여러번 반복해서 호출하기 때문이다. 만약 프로그램 실행이후 얼마간의 시간이 지나고 자주 사용되는 데이터를 L1에 올리고 나머지는 L2에 두고 사용하면 평균 액세스 시간이 단축되어 더욱 신속하게 데이터를 읽어올 수 있다.

위와 같은 현상을 **지역성의 원리(principle of locality)**라고 한다. 대부분의 프로그램에는 이 원리가 적용되기 때문에 L1계층의 메모리에 대한 액세스가 L2계층에 비해 많다. 다시말해 계층적 기억장치 구성은 프로그램의 성능을 끌어올려준다.

<br>
**2) 기억장치 계층**

아래 그림은 요즘의 컴퓨터에 적용된 계층적 기억장치 시스템을 보여준다.

![hierarchical_memory](/images/computer_architecture/5/hierarchical_memory.png){: width="60%" height="60%"}

위 그림에서 상위 계층으로 갈수록 아래의 특징이 뚜렷해진다.

**(a) 가격 상승**

**(b) 용량 감소**

**(c) 액세스 시간 단축**

**(d) CPU에 의한 액세스 빈도 상승**

<br>
특히 특징 (d)는 지역성의 원리를 활용하기 위한 계층적 기억장치의 특징을 가장 잘 나타낸다. 일반적으로 CPU 내부에는 일반목적, 특수목적 레지스터들이 수십개 정도(비싼 CPU의 경우 수백개) 있는데 레지스터의 경우에는 CPU 1클럭 주기 내에 데이터 액세스가 가능할 만큼 빠르다.

CPU만큼 빠르거나 주기억장치만큼 크지는 않은 **캐시 메모리(cache memory)**가 있다. 캐시는 프로그래머가 직접 다룰 수 없고 운영체제에 의해 자주 사용하는 데이터가 캐시 히트(cache hit)되어 캐시 메모리에 적재된다. 캐시는 CPU와 메모리 사이의 속도차이를 보완하기 위해 사용된다.

레지스터, 캐시, 메모리 사이의 액세스 시간에는 아래와 같은 관계가 성립된다.

	레지스터(~1ns) < 캐시(2~10ns) < 메모리(~100ns)
	
<br>
지금까지 설명한 이유들로 인해 계층적으로 기억장치를 구성하면 평균 액세스 시간은 단축시키고 전체적인 용량은 향상시키면서도 적절한 가격을 유지할 수 있다.

레지스터, 캐시, 주기억장치는 CPU가 주소를 지정하고 직접 액세스를 할 수 있는 내부 기억장치였다. 외부 기억장치(ex. SSD, CD-ROM, 하드디스크)는 장치의 제어기를 통하여서만 데이터 교환이 가능하다.

지금부터는 내부 기억장치에 초점을 맞춰 반도체 메모리와 캐시의 동작 및 원리에 대해 알아본다.

<br>
## 3. 반도체 기억장치 ##
----

아주 오래전에는 자기 코어로 만들어진 자화의 원리를 사용한 기억장치를 사용했지만, 전자공학의 발전 이후 메모리는 거의 반도체로 만들어진다.

<br>
**1) RAM**

RAM(Random Access Memorey)은 이름대로 임의 액세스를 하는 기억장치를 말한다. ROM(Read Only Memory)와 다르게 읽기와 쓰기가 모두 가능하다.

아래 그림과 같은 1K×8비트 용량의 RAM이 있다고 하자.

![RAM_block_diagram](/images/computer_architecture/5/RAM_block_diagram.png){: width="60%" height="60%"}

RAM의 워드(word)는 8bit이고, 1K(1024)개의 주소 지정이 가능하다. 따라서 사용할 수 있는 메모리 용량은 1KByte이다.

1024=2^10개의 주소지정을 위해서 주소 버스의 폭은 10비트가 필요하다. 또한 워드는 8bit이므로 데이터 교환을 위한 데이터 버스의 폭은 8bit이다.

위에서 CS(chip select) 비트는 여러개의 칩을 사용하는 기억장치 시스템에서 사용하는 칩 선택 신호이다. RD는 읽기 신호, WR는 쓰기 신호이다.

위 도표에서는 1이 될 때 해당 신호가 활성화(active-high) 된 것으로 가정하였다.실제 대부분의 칩에서는 0이 될 때 활성화되는 active-low 신호를 사용한다.)

RAM의 특징중 하나는 **휘발성(volatile)**이다. 전원 공급이 중단되면 데이터가 소멸된다. 즉, RAM은 일시적 기억장치로만 사용된다.

<br>
**※DRAM vs SRAM**

**a) DRAM(Dynamic RAM)**

DRAM은 데이터 저장을 위해 커패시터(capacitor)를 사용한다. 커패시터에 전하가 충전(charge)되어있으면 1, 아니면 0이다. 커패시터는 시간이 지남에따라 방전되는 성질로 인해 재충전이 필요하다.

**b) SRAM(Static RAM)**

SRAM은 데이터 저장을 위해 플립플롭(flip-flop)을 사용한다. 따라서 데이터가 안정된 상태로 유지될 수 있으므로 재충전이 필요하지 않다.

<br>
DRAM과 SRAM은 모두 전원공급이 중단되면 데이터를 잃는 휘발성이다. DRAM에 비해 SRAM은 소자 하나의 부피가 크고 가격이 비싸다. 따라서 같은 면적에 더 많은 셀을 얹을 수 있는 DRAM이 SRAM에비해 가격이 싸다. 그러나 SRAM은 반도체 소자인만큼 속도가 DRAM보다 빠르다. 이러한 특성으로 인해 DRAM은 일반적인 메모리로 사용되고 SRAM은 캐시로 사용된다.

<br>
RAM의 주소지정 원리를 보기 전 실제는 존재하지 않는 간단한 8×8비트 메모리의 주소지정에 대해 살펴보자.

![8by8_ram](/images/computer_architecture/5/8by8_ram.png){: width="60%" height="60%"}

8×8은 8개의 주소가 있고 각 주소당 8bit의 기억장소가 할당되는 메모리를 의미한다. 즉 총 용량은 64bit가 된다.

8개의 주소지정을 위해서는 3개의 주소선이 필요하다.(2^3=8) 해독기를 통하여 주소 비트가 해독되어 8개의 출력선들 중의 하나를 활성화시킨다. 이 메모리의 워드는 8비트이므로 데이터 교환을 위해서는 8비트 폭의 데이터 버스가 필요하다. 만약 이와같은 구조를 가지는 RAM의 전체 용량이 1Mbit(128K×8bit)라면 128K(128×2^10 = 2^17)개의 주소지정을 위해 17개의 주소선이 필요하다.

<br>
이제는 더 큰 용량의 메모리에 위 원리를 적용해보자. 다만 위에서는 기억장소들이 한 방향으로 선형적으로 나열되어있는 1차원 메모리를 가정하였으나 여기서는 2차원 메모리를 보여준다. 따라서 메모리의 주소지정을 위해서는 행(row) 주소와 열(column)주소를 따로 사용한다.

![16Mby4_ram](/images/computer_architecture/5/16Mby4_ram.png){: width="60%" height="60%"}

위 그림에서는 행주소와 열주소가 각각 행주소 버퍼와 열주소 버퍼로 들어간다. 이후 각각이 행 주소 해독기와 열 주소 해독기에 의해 해독되어 기억장소를 선택한다.

그림에서는 기억소자가 총 16M(=2^24)개 존재한다. 따라서 주소지정을 위해서는 24비트의 주소선이 필요하다. 그러나 실제로는 12비트의 주소선만 있어도 된다. 그 이유는 아래의 타이밍도를 통해 살펴보자.

![dram_timing_flow](/images/computer_architecture/5/dram_timing_flow.png){: width="60%" height="60%"}

일단 CPU는 24비트의 메모리 주소를 생성한다. 그들 중 상위 12비트는 행주소로, 하위 12비트는 열주소로 사용된다.

RAS(Row Address Signal)과 CAS(Column Address Signal)는 메모리 제어기에 의해 발생되는 신호이다. 메모리 제어기는 먼저 RAS를 1(SET)로 만들어 행 주소부터 행주소버퍼에 래치시키고 그 다음 마찬가지로 CAS를 SET시켜 열주소를  열주소 버퍼에 래치시킨다. 이처한 동작으로 행주소와 열주소가 순차적으로 DRAM으로 보내지며 각각의 해독기에 의해 해독된다.

위 타이밍도에서 RD신호를 보면 행 주소가 래치되기 시작하는 순간부터 들어온다. 그러나 실제 데이터가 읽히는 시간은 열 주소가 래치되기 시작하는 순간부터 액세스 시간을 지난 이후부터이다. 그 결과가 유효 데이터가 되어 데이터 버스에 실리게 된다.

또한 위 기억장치는 DRAM을 나타내기 때문에 재충전 장치가 존재한다. 메모리 액세스가 없는 사이클 동안 재충전 계수기는 0부터 4095까지의 주소를 순서대로 발생시키며 해당 행에있는 모든 기억소자를 재충전시킨다.

아래 그림은 위에서 설명한 16M×4 DRAM의 실제 칩 패키징 구조를 보여준다.

![16Mby4_ram_package](/images/computer_architecture/5/16Mby4_ram_package.png){: width="30%" height="30%"}

<br>
**2) ROM**

ROM(Read Only Memory)는 이름이 말해주듯이 읽기만 가능한 메모리이다. 대부분의 컴퓨터에서 메모리의 RAM 이외 일부는 ROM으로 구성된다.

또한 ROM은 비휘발성이다. 이러한 특성에 의해 ROM에는 아래와 같은 데이터가 주로 저장된다.

	a) 시스템 초기화 및 진단 프로그램
	b) 자주 사용되는 서브루틴
	c) 제어 유닛의 마이크로 프로그램
	
ROM에 저장될 데이터는 메모리 제조과정에서 미리 쓰여진다.

ROM은 한 번 쓰게되면 이후 수정이 불가능하다는 제한을 완화하기 위하여 이후 아래와 같은 ROM들이 추가적으로 개발되었다.

**a)PROM(Programmable ROM)**

제조 과정에서는 내용을 비워두며 사용자가 구입후에 필요한 데이터를 쓴다. ROM에 비해서는 융통성이 높지만 결국 한 번만 쓰기 가능하다는 점은 ROM과 같다.

**b) EPROM(Erasable Programmable ROM)**

내용 삭제가 가능하다. 하지만 삭제를 위해서는 자외선이 필요하다. 따라서 내용 삭제를 위해서는 메모리를 컴퓨터에서 분리해야한다. 또한 일부 삭제는 불가능하고 ROM의 전체 내용 삭제만 가능하다. 삭제하는데 수십분의 오랜 시간이 소요된다. 여러 번 삭제가 가능하다는 장점이 있다.

**c) EEPROM(Electrically Erasable PROM)**

EPROM과 다르게 전기적인 신호를 통해 내용을 삭제할 수 있으므로 메모리를 분리할 필요가 없다. 한 번에 바이트 단위의 수정이 가능하며 일반적으로 쓰기 횟수는 수만번 정도 가능하다.

**d) 플래시 메모리(Flash Memory)**

EEPROM과 마찬가지로 전기적인 신호를 통해 내용 수정이 가능하다. 그러나 내용 삭제 속도가 EEPROM에 비해 현저히 빠르다는 장점이 있다. 그러나 바이트 단위의 쓰기가 가능한 EEPROM과 달리 쓰기 동작이 페이지 단위(보통 4K 바이트)로만 가능하다.

<br>
## 4. 기억장치 모듈의 설계 ##
----

기억장치 칩 하나는 제한된 주소 갯수와 용량을 가지고 있다. 일반적인 메모리들은 이러한 칩 여러개를 물리적으로 접속시켜 사용한다. 물론 사용자가 보기에는 논리적으로 하나의 메모리처럼 보인다.

<br>
**1) 병렬 접속**

주소비트가 4개(0000~1111번지로 15개의 주소 지정)이고 주소 하나당 4bit를 저장하는 간단한 칩이 있다고 해보자. 그런데 CPU의 워드(word)가 8bit이다. 이런 경우 아래 그림과 같이 칩을 병렬로 접속해서 논리적으로 8bit인 메모리를 만들 수 있다.

![chip_parallel_joint](/images/computer_architecture/5/chip_parallel_joint.png){: width="50%" height="50%"}

4bit의 주소버스를 두 칩 주소버스에 공통적으로 연결한다. 그리고 8bit의 데이터를 4bit 나누어 칩의 데이터 버스와 연결했다. 이렇게 하면 두 메모리의 같은 위치에는 같은 번지가 배정되고 8bit의 데이터가 두개의 4bit로 쪼개져 각 칩의 기억장소에 저장된다.

이렇게 하면 16×4bit칩 2개로 16×8bit의 메모리를 구성할 수 있다.

좀 더 현실적인 예로 워드가 32bit(4byte)인 CPU를 사용하기 위해서 1K×8bit 칩으로 메모리를 구성한다면 아래 그림과 같이 4개를 병렬연결하면 된다. 이렇게 하면 1024개의 주소를 가지며 각 주소마다 32bit 크기의 기억장소를 가지는 메모리가 된다.

![chip_parallel_joint2](/images/computer_architecture/5/chip_parallel_joint2.png){: width="50%" height="50%"}

<br>
**2) 직렬 접속**

직렬접속을 사용하면 병렬접속과 달리 기억장소의 수를 확장시킬 수 있다. 아래 그림은 16×4bit 칩 2개를 직렬 연결하여 32×4bit의 메모리를 구성한 것이다.

![chip_serial_joint](/images/computer_architecture/5/chip_serial_joint.png){: width="50%" height="50%"}

32개(2^5)의 주소를 위해서는 5bit의 주소버스가 필요하다. 이 중 최상위 1bit는 각 칩의 선택 신호(CS-bar)에 인가되었다. CS-bar신호의 bar(CS신호 기호 위에있는 직선)는 active-low를 나타낸다. 즉, 이 신호는 0이 들어올 때 활성화가 된다는 뜻이다. 다시말해 0이 들어오면 칩이 선택되었단 것이다. 또한 데이터버스는 각각의 칩에 공통적으로 인가되었다.

이 때 주소의 최상위비트(A4)가 0이면 RAM1이 선택되고, 1이면 RAM2가 선택된다. 따라서 총 32개의 주소를 사용할 수 있는 것이다.

	RAM1 : 00000~01111번지
	RAM2 : 10000~11111번지

<br>
아래 그림은 1K×8bit chip 4개를 직렬 연결하여 4K×8bit의 메모리를 구성한 것이다.

![chip_serial_joint2](/images/computer_architecture/5/chip_serial_joint2.png){: width="50%" height="50%"}

1K(2^10)이 4K(2^12)이 되기 위해서는 2개의 주소bit가 추가적으로 필요하다. 상위 2비트는 칩 선택 신호로 사용하고 나머지 10비트는 각 칩에 공통적으로 인가한다.

2개의 추가 주소비트를 2×4 해독기의 입력으로 넣어주면 4개의 신호로 구분될 수 있다. 그리고 각 신호가 4개 칩의 CS비트로 인가된다. 두 비트가 00, 01, 10, 11일 경우 각각 RAM1, RAM2, RAM3, RAM4가 선택된다.

예를들어 RAM3에는 1000 0000 0000 번지부터 1011 1111 1111번지까지 주소가 할당된다.

<br>

직렬접속과 병렬접속을 조합하면 우리가 원하는 주소폭과 데이터폭을 가지는 메모리를 설계할 수 있다.

<br>
## 5. 캐시 메모리 ##
----

앞에서 언급했지만 캐시(cache) 메모리는 CPU와 메모리 사이의 속도차이로인한 성능 저하를 방지하기 위해 사용하는 반도체 메모리이다. 캐시는 메모리보다 CPU에 인접하거나 CPU 내부에 포함시키기도 한다.

프로그램 실행동안 메모리에서 자주 인출되는 명령어나 데이터가 캐시에 올라가게 된다. 캐시는 메모리보다 비싼 고속 기억장치이기도 하며 물리적으로 CPU와 더 가깝기 때문에 메모리보다 액세스 시간이 짧다. 비싸면서 설치 공간의 제한때문에 주기억장치의 용량에 비해 매우 작다.

![cache_memory_position](/images/computer_architecture/5/cache_memory_position.png){: width="50%" height="50%"}

일단 CPU가 메모리로부터 인출한 명령어나 데이터는 캐시에 적재(load)된다. 따라서 일정시간 경과 후에는 CPU가 한 번 이상 액세스한 내용은 캐시에 복사되어있는 상태가 된다. 그러나 캐시는 용량이 작기 때문에 계속 캐시에 남아있지는 못한다.

일단 캐시에 데이터가 적재되면 메모리에 비해 액세스 시간이 매우 짧아진다. CPU가 데이터에 엑세스 할 때는 캐시부터 검사 후 없으면 메모리로 이동한다.

<br>

CPU가 데이터를 캐시에서 찾는것을 성공했을 경우를 **캐시 적중(cache hit)**라고 한다.(보통 캐시 히트라고 한다.) 반대로 캐시에서 찾지 못한 경우를 **캐시 미스(cache miss)**라고 한다.

**캐시 적중률(cache hit ratio)**는 CPU가 캐시히트를 할 확률이다. 풀어말하면 CPU가 데이터에 액세스 했을 때 그 데이터를 캐시로부터 찾았을 확률이며 아래와 같은 수식으로 나타낸다.

$$mathbf{H} = mathbf{캐시 히트 횟수} \over mathbf{전체 기억장치 액세스 횟수}$$

이를 응용하면 CPU의 기억장치 평균 액세스 시간도 계산할 수 있다.

$$mathbf{T}_a = mathbf{H} \times \p mathbf{1-H} \times mathbf{T}_m$$

<br>
## 6. DDR SDRAM ##
----

<br>
## 7. 차세대 비휘발성 기억장치 ##
----